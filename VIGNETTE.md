# The Architecture and Utility of coreason-council

### 1. The Philosophy (The Why)

**coreason-council** acts as the "Senate" for cognitive architectures, addressing a critical flaw in single-model systems: the propensity for hallucination and bias when relying on a solitary weight distribution. It operates on the principle of **Ensemble Reasoning**, posits that while one Large Language Model (LLM) may err, a diverse coalition of models critiquing one another will converge on the truth.

The package implements a strict **Divergence-Convergence Loop** to ensure robust decision-making:
*   **Diversity by Design:** It rejects "groupthink" by enforcing the use of distinct personas (Proposers) who generate initial ideas in **Blind Independence**.
*   **Adversarial Review:** Agreement is viewed with suspicion. The system actively seeks dissent via a "Dissenter" component that calculates **Semantic Entropy**.
*   **Semantic Aggregation:** It moves beyond simple voting. The final output is a synthesis that incorporates the strongest elements of conflicting viewpoints, generated by an "Aggregator" (The Judge).

By orchestrating **Mixture-of-Agents (MoA)** topologies, `coreason-council` provides the "System 2" reflective capability required for high-stakes reasoning.

### 2. Under the Hood (The Dependencies & logic)

The stack is chosen to support the "Glass Box" observability standard, ensuring that every consensus decision is traceable and typed.

*   **`pydantic`**: The backbone of the system. It defines rigid data models for `ProposerOutput`, `Critique`, and `Verdict`. This ensures that the "fuzzy" output of LLMs is constrained into valid, serializable structures suitable for downstream automation.
*   **`instructor`**: Used to interface with LLMs (like OpenAI's models). It forces models to output structured JSON that matches the Pydantic schemas, turning text generation into typed function calls.
*   **`loguru`**: Provides high-fidelity logging, essential for tracing the complex asynchronous interactions between multiple agents during a debate.
*   **`typer`**: Facilitates the command-line interface, allowing the Council to be run as a standalone utility.

**The Internal Logic:**
The heart of the system is the **`ChamberSpeaker`** (The Orchestrator). It manages a state machine that transitions through three phases:
1.  **Proposal:** Agents generate answers in parallel isolation to prevent anchoring bias.
2.  **Debate (The Loop):** A **`Dissenter`** scans the proposals. If the "Semantic Entropy" (disagreement) is above a threshold, it triggers a peer-critique round where agents attack each other's logic. This loops until consensus is reached or a deadlock occurs.
3.  **Aggregation:** An **`Aggregator`** synthesizes the final history into a single `Verdict`, complete with confidence scores and citations.

### 3. In Practice (The How)

The following example demonstrates how to convene a Council session using the `ChamberSpeaker`. For clarity, we use Mock components, but in production, these would be backed by `LLMProposer`, `JaccardDissenter` (or LLM-based), and `LLMAggregator`.

```python
import asyncio
from coreason_council.core.speaker import ChamberSpeaker
from coreason_council.core.proposer import MockProposer
from coreason_council.core.dissenter import MockDissenter
from coreason_council.core.aggregator import MockAggregator
from coreason_council.core.models.persona import Persona

async def convene_council():
    # 1. Define the Roster (The Voices)
    personas = [
        Persona(name="The Optimist", system_prompt="Focus on benefits."),
        Persona(name="The Skeptic", system_prompt="Focus on risks.")
    ]
    proposers = [MockProposer(), MockProposer()]

    # 2. Initialize the Orchestrator
    # The Speaker manages the debate loop, entropy checks, and final judgment.
    speaker = ChamberSpeaker(
        proposers=proposers,
        personas=personas,
        dissenter=MockDissenter(default_entropy_score=0.8), # Simulating initial disagreement
        aggregator=MockAggregator(),
        max_rounds=3
    )

    # 3. Resolve a Query
    # The system will detect high entropy, force a debate, and then aggregate.
    query = "Should we deploy to production on Friday?"
    verdict, trace = await speaker.resolve_query(query)

    print(f"Final Verdict: {verdict.content}")
    print(f"Confidence: {verdict.confidence_score}")
    print(f"Rounds taken: {len(trace.transcripts) // len(proposers)}") # Approximation of rounds

if __name__ == "__main__":
    asyncio.run(convene_council())
```

**What is happening here?**
*   We instantiate a **`ChamberSpeaker`** with two opposing personas.
*   We force a "debate" scenario by setting the `MockDissenter` to report high entropy (0.8).
*   The `resolve_query` method kicks off the lifecycle: agents propose, the dissenter flags disagreement, agents critique each other (simulated), and finally, the `Aggregator` yields a consensus `Verdict`.
*   The returned `trace` object contains the full transcript of the session, ready for inspection.
